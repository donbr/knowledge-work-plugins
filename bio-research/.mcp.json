{
  "mcpServers": {
    "pubmed": {
      "type": "http",
      "url": "https://pubmed.mcp.claude.com/mcp"
    },
    "biorender": {
      "type": "http",
      "url": "https://mcp.services.biorender.com/mcp"
    },
    "biorxiv": {
      "type": "http",
      "url": "https://mcp.deepsense.ai/biorxiv/mcp"
    },
    "c-trials": {
      "type": "http",
      "url": "https://mcp.deepsense.ai/clinical_trials/mcp"
    },
    "chembl": {
      "type": "http",
      "url": "https://mcp.deepsense.ai/chembl/mcp"
    },
    "synapse": {
      "type": "http",
      "url": "https://mcp.synapse.org/mcp"
    },
    "wiley": {
      "type": "http",
      "url": "https://connector.scholargateway.ai/mcp"
    },
    "owkin": {
      "type": "http",
      "url": "https://mcp.k.owkin.com/mcp"
    },
    "ot": {
      "type": "http",
      "url": "https://mcp.platform.opentargets.org/mcp"
    },
    "benchling": {
      "type": "http",
      "url": ""
    },
    "life-sciences": {
      "type": "http",
      "url": "",
      "_comment": "Fuzzy-to-Fact life sciences gateway (HGNC, UniProt, Ensembl, NCBI, ChEMBL, PubChem, IUPHAR, STRING, BioGRID, WikiPathways, OpenTargets, ClinicalTrials). Source: https://github.com/donbr/lifesciences-research"
    },
    "cq-eval": {
      "type": "stdio",
      "command": "python",
      "args": ["mcp-servers/cq-eval/server.py"],
      "_comment": "Competency Question golden test set management and scoring. Validates data federation accuracy against gold standard mechanistic paths."
    }
  }
}
